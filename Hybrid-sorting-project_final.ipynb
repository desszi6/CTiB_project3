{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid sorting\n",
    "\n",
    "In this project, you will experiment with two sorting algorithms, compare their running time, and build a hybrid algorithm based on your experimental results.\n",
    "\n",
    "If you want to use the code for running time experiments that I have put in this Notebook, you will need to import these modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numpy.random as ran\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use my plotting code, you also need to include these models. If you have installed `miniconda` and not the full `conda` distribution, you might not have these modules. If that is the case, you can open a terminal and install them with this commands:\n",
    "\n",
    "```sh\n",
    "conda install pandas seaborn\n",
    "```\n",
    "\n",
    "You need to do this before you can evaluate the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quicksort\n",
    "\n",
    "The algorithm *quick sort* is a divide and conquer sorting algorithm that has an expected running time of $O(n\\log n)$. The *expected* qualifier is there because the running time analysis is based on probabilistic assumptions. We will get to this in a bit. It is called *quick* because it uses very few operations compared to other divide-and-conquer sorting algorithms.\n",
    "\n",
    "The algorithm works like this. If you want to sort an array (e.g. a Python list) from index $i$ to index $j$, then you pick a random element in this interval. Let us call it $p$ for *pivot*. We partition the items in `x[i:j]` (in place) such that the leading elements in the partitioning are all less than or equal to the pivot and all elements in the last part of the array are larger than the pivot. Since the pivot is selected from the elements in `x[i:j]`, the first part of the partitioning cannot be empty; the last part can. Let us call the last index in the first part $k$ and make the additional requirement that `x[k]` equals the pivot.\n",
    "\n",
    "![](partitioning.png)\n",
    "\n",
    "This partitioning can be used to break down the search problem into two sub-parts. Since all the elements in the first part are less than all items in the second part, we can sort the two segments independently. We can do this recursively. By requiring that the pivot is placed at `x[k],` we can leave that element out of the recursion which will guarantee that the recursive function never recurses on the same sequence as it was called with.\n",
    "\n",
    "The algorithm looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qsort_rec(x, i, j):\n",
    "    if j - i <= 1: \n",
    "        # x[i:j] is [] or [e] -> so already sorted\n",
    "        return\n",
    "    k = partition(x, i, j)\n",
    "#    print(x)\n",
    "    qsort_rec(x, i, k-1)\n",
    "    qsort_rec(x, k, j)\n",
    "\n",
    "def qsort(x):\n",
    "    qsort_rec(x, 0, len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "\n",
    "x = list(ran.randint(10, size = n))\n",
    "\n",
    "print(x)\n",
    "\n",
    "qsort(x)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The runtime analysis goes like this: If the pivot is chosen at random then the two parts of the partition are expected to be roughly equal in length. If we can handle the partitioning in linear time the runtime recurrence is then\n",
    "\n",
    "$$T(n) = 2T(n/2) + O(n)$$\n",
    "\n",
    "which we know is $O(n\\log n)$. If we are unlucky in our selection of pivots, one of the partitions will be empty and the other contain $n-1$ elements (we eliminate `x[k]` in each recursion but no more). In that case we get the recurrence $T(n) = T(n-1) + O(n)$ which is $O(n^2)$. If we pick the pivot at random, we can still be unlucky but only with low probability.\n",
    "\n",
    "Sampling a random pivot from the sequence is potentially slow, so we often just pick the first element. This can hurt the running time substantially if the input is already close to sorted; then the first element is likely to be among the smallest values in the range and the partitioning will be uneven. Another approach is to pick a few elements at fixed indices, e.g. the first, the last and the middle element, and then pick the median of this. On pathological input, this can give us a quadratic running time, but it is less likely.\n",
    "\n",
    "If you like the median of three points, you might find this function useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median3(x, y, z):\n",
    "    if min(y,z) <= x <= max(y,z): return x\n",
    "    if min(x,z) <= y <= max(x,z): return y\n",
    "    if min(x,y) <= z <= max(x,y): return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Implement the partitioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(x, i, j):\n",
    "    \"\"\"\n",
    "    Let pivot = x[i]. This function will\n",
    "    arrange x[i:j] into x'[i:k] + x'[k:j] such that\n",
    "    x'[h] <= pivot for h = i ... k and\n",
    "    x'[k] == pivot and\n",
    "    x'[h] > pivot for h = k + 1 ... j\n",
    "    and then returns this k\n",
    "    \"\"\"\n",
    "    lower = []\n",
    "    higher = []\n",
    "    p=x[i]\n",
    "    for n in x[i+1:j]:\n",
    "        if n <= p:\n",
    "            lower.append(n)\n",
    "#            print(lower)\n",
    "        else:\n",
    "            higher.append(n)\n",
    "#            print(higher)\n",
    "    lower.append(p)\n",
    "    x[i:j] = lower + higher\n",
    "#    print(p,lower,higher,x, len(lower)+i)\n",
    "    return len(lower)+i\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test how fast the `qsort` function is, we can compare it to the `insertion_sort` algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insertion_sort(x):\n",
    "    for i in range(1,len(x)):\n",
    "        j = i\n",
    "        while j > 0 and x[j-1] > x[j]:\n",
    "            x[j-1], x[j] = x[j], x[j-1]\n",
    "            j -= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this function to collect time information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_algorithms(ns, sort_algs):\n",
    "    \"\"\"\n",
    "    Run each sort-algorithm implemented in functions and\n",
    "    provided in `sort_algs` on random lists of length\n",
    "    n for each n in `ns`.\n",
    "    \n",
    "    Returns a Pandas DataFrame that we can use for plotting\n",
    "    or extracting summary data.\n",
    "    \"\"\"\n",
    "    algs, ns_, times = [], [], []\n",
    "    for n in ns:\n",
    "        x = list(ran.randint(10, size = n))\n",
    "        for alg in sort_algs:\n",
    "            x_copy = x[:]\n",
    "            start = timer()\n",
    "            alg(x_copy)\n",
    "            end = timer()\n",
    "            \n",
    "            algs.append(alg.__name__)\n",
    "            ns_.append(n)\n",
    "            times.append(end - start)\n",
    "            #print(alg,n,x)\n",
    "            assert sorted(x) == x_copy\n",
    "    \n",
    "    return pd.DataFrame({'alg': algs, 'n': ns_, 'time': times})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below runs the `qsort` and the `insertion_sort` on a range of sizes, collected in the list `ns`. For each combination of sort-function and `n` we replicate the time measurements `no_reps` times. YOu can modify the setup to your heart's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "algs = [qsort, insertion_sort]\n",
    "no_reps = 5\n",
    "min_n, max_n = 1, 200\n",
    "ns = []\n",
    "for n in range(min_n, max_n):\n",
    "    ns.extend([n] * no_reps)\n",
    "    print(x)\n",
    "time_measures = time_algorithms(ns, algs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have collected the time measurements we can plot it using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x = 'n', y = 'time', hue = 'alg', lowess = True,\n",
    "           x_jitter = 0.1, markers='.',\n",
    "           data = time_measures)\n",
    "g.set(ylim = (0, max(time_measures['time'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tail-recursion optimization\n",
    "\n",
    "You call `qsort` twice in the implementation above. \n",
    "\n",
    "**Exercise:** Make a modified version that uses the tail-recursion optimization.\n",
    "**Exercise:** Compare its running time with the one that doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qsort_rec(x, i, j):\n",
    "    if j - i <= 1: \n",
    "        # x[i:j] is [] or [e] -> so already sorted\n",
    "        return\n",
    "    k = partition(x, i, j)\n",
    "    qsort_rec(x, i, k-1)\n",
    "    qsort_rec(x, k, j)\n",
    "\n",
    "def qsort(x):\n",
    "    qsort_rec(x, 0, len(x))\n",
    "    \n",
    "def qsort_shit(x, i, j):\n",
    "# works with almost the same running time and does both sides\n",
    "    while i < j:\n",
    "        k = partition(x, i, j)\n",
    "        if k < (j - i) / 2:\n",
    "            qsort_shit(x, i, k - 1)\n",
    "            i += 1\n",
    "        else:\n",
    "            qsort_shit(x, k + 1, j)\n",
    "            j = k - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "\n",
    "x = list(ran.randint(10, size = n))\n",
    "\n",
    "\n",
    "print(x)\n",
    "\n",
    "qsort(x)\n",
    "#qsort(x)\n",
    "\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A hybrid algorithm\n",
    "\n",
    "When you compare quick-sort with insertion sort, the likely result—the result I get and the result that people usually get—is that insertion sort is faster for short sequences while quick-sort is faster on longer sequences. The reason is that quick-sort, although it has very little overhead compared to other divide-and-conquer algorithms, does pay a hefty price for the recursive calls. Insertion sort does not, but it does run in $O(n^2)$ so when the length of the input is sufficiently large, it will be slower.\n",
    "\n",
    "A common trick is then to use a hybrid sorting algorithm. We use quick-sort to partition the input into short segments such that all elements in one segment is larger than all elements in the previous segment and smaller than all the elements in the next segment.\n",
    "\n",
    "![](segmented.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Prove that you can obtain this segmentation by adding a threshold to `qsort` so it does not continue the sorting after the length of the sequence `x[i:j]` is below this threshold.\n",
    "\n",
    "If we impose a threshold of x and our base case is dependent on this ( if j-i <= x), the recursion is going to stop when x[i:j] <= x, because x[i:j] == j-i.\n",
    "\n",
    "This is going to result in the described segmentation as long as the returned k works as described by the partitioning algorithm, as k is the position in the list where all values to the right of it are of higher value, and all on the left are of equal or lesser value.\n",
    "\n",
    "\n",
    "**Exercise:** Implement a quick-sort that stops at a parameterized threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qsort_rec(x, i, j, threshold):\n",
    "    if j-i <= threshold:\n",
    "        return\n",
    "    k = partition(x, i, j)\n",
    "    qsort_rec(x, i, k-1, threshold)\n",
    "    qsort_rec(x, k, j,threshold)\n",
    "\n",
    "def qsort(x, threshold = 1):\n",
    "    qsort_rec(x, 0, len(x),threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20\n",
    "\n",
    "x = list(ran.randint(10, size = n))\n",
    "\n",
    "\n",
    "print(x)\n",
    "\n",
    "qsort(x)\n",
    "#qsort(x)\n",
    "\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def qsort_rec(x, i, j, threshold):\n",
    "    pass\n",
    "\n",
    "def qsort(x, threshold = 1):\n",
    "    qsort_rec(x, 0, len(x), threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the hybrid algorithm runs quick-sort down to a given threshold and then uses insertion sort for the rest. You could implement this by switching to insertion sort from quick-sort when you reach the threshold, but an easier approach is to first segment the input using quick-sort with the threshold and then run insertion sort on the entire sequence. The result is the same.\n",
    "\n",
    "Based on your experiments above, you should be able to see where the two algorithms switch in running time. Try to put the threshold around that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hybrid(x):\n",
    "    qsort_rec(x, 0, len(x), threshold = 15)\n",
    "    insertion_sort(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add the hybrid algorithm to your functions and measure its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algs2 = [qsort, insertion_sort, hybrid]\n",
    "time_measures2 = time_algorithms(ns, algs2)\n",
    "sns.lmplot(x = 'n', y = 'time', hue = 'alg', lowess = True,\n",
    "           x_jitter = 0.1, markers='.',\n",
    "           data = time_measures2)\\\n",
    ".set(ylim = (0, max(time_measures2['time'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to, you can try to run the algorithms on longer sequences. Depending on your implementation, the switch between the `qsort` and the `hybrid` algorithm might vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_reps = 5\n",
    "min_n, max_n, step = 1, 100, 10\n",
    "large_ns = []\n",
    "for n in range(min_n, max_n, step):\n",
    "    large_ns.extend([n] * no_reps)\n",
    "time_measures3 = time_algorithms(large_ns, algs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'n', y = 'time', hue = 'alg', lowess = True,\n",
    "               x_jitter = 0.1, markers='.',\n",
    "               data = time_measures3) \\\n",
    ".set(ylim = (0, max(time_measures3['time'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, where we saw the switch in running time we saw in the earlier experiments, were on random input sequences. But insertion sort is more efficient on almost sorted sequences, so the optimal threshold might be larger than the one we chose from those experiments.\n",
    "\n",
    "You can use the function below to create functions that use different threshold but otherwise have the same interface as the other functions we do experiments on. (We cannot add parameters to the functions we use in `time_algorithms` so we need to wrap the hybrid algorithms this way; that is the only reason why we do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_hybrid(threshold):\n",
    "    def hybrid(x):\n",
    "        qsort_rec(x, 0, len(x), threshold)\n",
    "        insertion_sort(x)\n",
    "    hybrid.__name__ = 'Threshold: {:>4}'.format(threshold)\n",
    "    return hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can experiment with different choices of threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thresholds = list(range(10,100,20)) + list(range(100,225,25))\n",
    "hybrid_algs = [make_hybrid(th) for th in thresholds]\n",
    "time_measures4 = time_algorithms(large_ns, hybrid_algs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x = 'n', y = 'time', hue = 'alg', lowess = True,\n",
    "               x_jitter = 0.1, markers='.',\n",
    "               data = time_measures4)\n",
    "g.set(ylim = (0, max(time_measures4['time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_reps = 5\n",
    "min_n, max_n, step = 100, 1000, 100\n",
    "sparse_ns = []\n",
    "for n in [1, 10] + list(range(min_n, max_n, step)):\n",
    "    sparse_ns.extend([n] * no_reps)\n",
    "time_measures5 = time_algorithms(sparse_ns, hybrid_algs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x = 'n', y = 'time', hue = 'alg', lowess = True,\n",
    "               x_jitter = 0.1, markers='.',\n",
    "               data = time_measures5)\n",
    "g.set(ylim = (0, max(time_measures5['time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_thresholds = [10, 25, 50]\n",
    "large_thresholds = [100, 150, 200]\n",
    "thresholds2 = small_thresholds + large_thresholds\n",
    "no_reps = 100 # more repetitions to get better mean estimate\n",
    "few_ns = [] \n",
    "for n in [10, 100, 500, 1000, 1500, 2000]:\n",
    "    few_ns.extend([n] * no_reps)\n",
    "hybrid_algs2 = [make_hybrid(th) for th in thresholds2]\n",
    "time_measures6 = time_algorithms(few_ns, hybrid_algs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x = 'n', y = 'time', hue = 'alg', lowess = True,\n",
    "               x_jitter = 0.1, markers='.',\n",
    "               data = time_measures6)\n",
    "g.set(ylim = (0, max(time_measures6['time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_time = time_measures6 \\\n",
    "    .groupby(['alg','n'], as_index = False) \\\n",
    "    .agg('mean') \\\n",
    "    .reset_index()\n",
    "sns.lineplot(x = 'n', y = 'time', hue = 'alg', data = mean_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Experiment with choices of threshold and find the best you can. Doing something like this is called *algorithmic engineering*. It is not about designing new algorithms but about finding optimal implementations by mixing them and by choosing good parameters.\n",
    "\n",
    "The optimal threshold really depends on the length of the list. We can see that a threshold of 50 is optimal for n<=500, a threshold of 100 is optimal for 500<n<1000, a threshold of 150 for 1000 < n < 1500, and for n>1500 the optimal threshold is 200, this probably keeps changing as the size of the data increases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the experiments have started with random lists. The results are potentially misleading if the list is already mostly sorted. You can use the function below to create almost sorted lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def almost_sorted(n, fraction_moved = 0.2):\n",
    "    m = int(fraction_moved * n)\n",
    "    x = list(range(n))\n",
    "    idx1, idx2 = sample(range(n), m), sample(range(n), m)\n",
    "    for i,j in zip(idx1, idx2):\n",
    "            x[i], x[j] = x[j], x[i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_algorithms_almost_sorted(ns, sort_algs):\n",
    "    \"\"\"\n",
    "    Run each sort-algorithm implemented in functions and\n",
    "    provided in `sort_algs` on random lists of length\n",
    "    n for each n in `ns`.\n",
    "    \n",
    "    Returns a Pandas DataFrame that we can use for plotting\n",
    "    or extracting summary data.\n",
    "    \"\"\"\n",
    "    algs, ns_, times = [], [], []\n",
    "    for n in ns:\n",
    "        x = almost_sorted(n)\n",
    "        for alg in sort_algs:\n",
    "            x_copy = x[:]\n",
    "            start = timer()\n",
    "            alg(x_copy)\n",
    "            end = timer()\n",
    "            \n",
    "            algs.append(alg.__name__)\n",
    "            ns_.append(n)\n",
    "            times.append(end - start)\n",
    "            #print(alg,n,x)\n",
    "            assert sorted(x) == x_copy\n",
    "    \n",
    "    return pd.DataFrame({'alg': algs, 'n': ns_, 'time': times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_thresholds = [1, 10, 25, 50]\n",
    "large_thresholds = [100, 150, 200]\n",
    "thresholds2 = small_thresholds + large_thresholds\n",
    "no_reps = 100 # more repetitions to get better mean estimate\n",
    "few_ns = [] \n",
    "for n in [10, 100, 500, 1000, 1500, 2000]:\n",
    "    few_ns.extend([n] * no_reps)\n",
    "hybrid_algs2 = [make_hybrid(th) for th in thresholds2]\n",
    "time_measures6 = time_algorithms_almost_sorted(few_ns, hybrid_algs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.lmplot(x = 'n', y = 'time', hue = 'alg', lowess = True,\n",
    "               x_jitter = 0.1, markers='.',\n",
    "               data = time_measures6)\n",
    "g.set(ylim = (0, max(time_measures6['time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_time = time_measures6 \\\n",
    "    .groupby(['alg','n'], as_index = False) \\\n",
    "    .agg('mean') \\\n",
    "    .reset_index()\n",
    "sns.lineplot(x = 'n', y = 'time', hue = 'alg', data = mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(almost_sorted(10))\n",
    "print(almost_sorted(10))\n",
    "print(almost_sorted(10, 0.9))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Experiment with almost sorted lists and compare with the results for random lists.\n",
    "\n",
    "To experiment with this we created a \"new\" time_algorithms, that uses the almost_sorted function to create its list, you can run this above. In this case it seems that the dependency on the insertion sort is reduced as speed increases as we reduce the threshold. Where with completely random lists we see that higher thresholds are more efficient at high n's. We tried to completely remove the insertion sort, by putting the threshold at 1, but this, unsurprisingly, yielded a slower time than the threshold = 10, because insertion sort sorts short lists fast like the devil."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6b4edfe8f5b63aad8d5fd22163b1b34a2a814ee0f50c40673c64e6089f508cae"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
